AI Proctoring System (Real-Time Monitoring)
ğŸ“Œ Project Overview

This project is a real-time AI-based proctoring system built to monitor online examinations or assessments.
It uses computer vision and deep learning to detect suspicious activities such as the use of electronic devices or the presence of multiple people.

The system shows a clean live video feed and generates a detailed report after the session ends.

ğŸ¯ Key Objectives

Monitor candidates during online exams

Detect electronic devices (mobile, laptop, tablet, etc.)

Detect multiple faces or absence of face

Avoid showing confidence or predictions during live monitoring

Generate an unbiased and professional final report

ğŸ§  Technologies Used

Python

Streamlit â€“ for web interface

OpenCV â€“ for webcam and face detection

YOLOv8 â€“ for object detection

SQLite â€“ for logging session data

NumPy & Pandas â€“ for analysis and reporting

âš™ï¸ System Features
ğŸ”´ Live Monitoring

Real-time webcam feed

Face detection using Haar Cascade

Object detection for malpractice-related devices

No confidence scores or labels shown on screen

Neutral bounding boxes only

ğŸ“± Malpractice Detection

Detects the following electronic devices:

Mobile phone

Laptop

Tablet

Headphones

Remote control

Multiple devices in the same frame are treated as a malpractice event.

ğŸ“„ Final Proctoring Report

Generated after monitoring stops:

Session duration

Multiple face detection count

No-face detection count

Electronic device detection summary

Multiple device events

Overall detection confidence score

Professional confidence disclosure

ğŸ”’ Confidence Handling (Important Design Choice)

Confidence scores are hidden during live monitoring

Confidence is calculated in the backend

Final confidence is shown only in the report

This avoids bias and misleading real-time interpretation

ğŸ“‚ Project Structure
realtime_proctoring_system/
â”‚
â”œâ”€â”€ app.py                    # Streamlit application
â”œâ”€â”€ object_detection.py       # YOLO-based object detection
â”œâ”€â”€ generate_report.py        # Offline report generation
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ emotion_logs.db       # SQLite database
â”œâ”€â”€ models/
â”‚   â””â”€â”€ yolov8n.pt
â””â”€â”€ README.md

â–¶ï¸ How to Run the Project
1ï¸âƒ£ Install dependencies
pip install streamlit opencv-python ultralytics pandas numpy

2ï¸âƒ£ Start the application
streamlit run app.py

3ï¸âƒ£ Generate offline report (optional)
python generate_report.py

ğŸ“Š Overall Detection Confidence

Calculated as the average of frame-level object detection confidence

Displayed only in the final report

Helps in audit and review without affecting live monitoring

ğŸ“ Academic / Viva Explanation

â€œLive confidence scores are intentionally suppressed to avoid bias.
All detections are logged per frame and aggregated into a final report that includes an overall detection confidence.â€

âœ… Advantages of This System

Real-time monitoring

Bias-free evaluation

Professional reporting

Scalable and modular design

Suitable for academic projects and demos

ğŸš€ Future Enhancements

PDF report export

Evidence image capture

Emotion analysis summary

Confidence trend charts

Multi-person tracking timeline